{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from utils.logger import LOGPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>conv</th>\n",
       "      <th>epoch_best</th>\n",
       "      <th>epoch_learn</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>mem_ram_train</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>f1macro_train</th>\n",
       "      <th>f1micro_train</th>\n",
       "      <th>f1macro_val</th>\n",
       "      <th>f1micro_val</th>\n",
       "      <th>f1macro_test</th>\n",
       "      <th>f1micro_test</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_ram_eval</th>\n",
       "      <th>mem_cuda_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>cora</td>\n",
       "      <td>Iterative</td>\n",
       "      <td>AdjConv</td>\n",
       "      <td>63</td>\n",
       "      <td>500</td>\n",
       "      <td>4.1765</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.059</td>\n",
       "      <td>92.248</td>\n",
       "      <td>93.169</td>\n",
       "      <td>88.792</td>\n",
       "      <td>90.037</td>\n",
       "      <td>87.530</td>\n",
       "      <td>89.094</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>cora</td>\n",
       "      <td>Iterative</td>\n",
       "      <td>AdjConv</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>4.0485</td>\n",
       "      <td>1.128</td>\n",
       "      <td>0.059</td>\n",
       "      <td>75.728</td>\n",
       "      <td>85.231</td>\n",
       "      <td>73.496</td>\n",
       "      <td>83.764</td>\n",
       "      <td>72.777</td>\n",
       "      <td>81.331</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>1.128</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>cora</td>\n",
       "      <td>Iterative</td>\n",
       "      <td>AdjConv</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>4.0349</td>\n",
       "      <td>1.132</td>\n",
       "      <td>0.059</td>\n",
       "      <td>76.519</td>\n",
       "      <td>85.908</td>\n",
       "      <td>70.762</td>\n",
       "      <td>79.705</td>\n",
       "      <td>76.251</td>\n",
       "      <td>86.876</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>1.132</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>cora</td>\n",
       "      <td>Iterative</td>\n",
       "      <td>ChebConv</td>\n",
       "      <td>47</td>\n",
       "      <td>500</td>\n",
       "      <td>6.4711</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.071</td>\n",
       "      <td>99.386</td>\n",
       "      <td>99.508</td>\n",
       "      <td>69.611</td>\n",
       "      <td>73.432</td>\n",
       "      <td>73.348</td>\n",
       "      <td>75.416</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>cora</td>\n",
       "      <td>Iterative</td>\n",
       "      <td>ChebConv</td>\n",
       "      <td>46</td>\n",
       "      <td>500</td>\n",
       "      <td>6.2731</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0.071</td>\n",
       "      <td>98.865</td>\n",
       "      <td>99.077</td>\n",
       "      <td>72.122</td>\n",
       "      <td>75.461</td>\n",
       "      <td>73.184</td>\n",
       "      <td>75.231</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>21</td>\n",
       "      <td>penn94</td>\n",
       "      <td>DecoupledFixedCompose</td>\n",
       "      <td>Adji2Conv,Adji2Conv-gaussian,gaussian</td>\n",
       "      <td>287</td>\n",
       "      <td>500</td>\n",
       "      <td>107.7445</td>\n",
       "      <td>3.517</td>\n",
       "      <td>1.861</td>\n",
       "      <td>81.109</td>\n",
       "      <td>81.124</td>\n",
       "      <td>77.627</td>\n",
       "      <td>77.638</td>\n",
       "      <td>76.942</td>\n",
       "      <td>76.981</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>3.517</td>\n",
       "      <td>1.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>22</td>\n",
       "      <td>penn94</td>\n",
       "      <td>DecoupledFixedCompose</td>\n",
       "      <td>Adji2Conv,Adji2Conv-gaussian,gaussian</td>\n",
       "      <td>37</td>\n",
       "      <td>500</td>\n",
       "      <td>106.8353</td>\n",
       "      <td>3.517</td>\n",
       "      <td>1.861</td>\n",
       "      <td>67.480</td>\n",
       "      <td>67.547</td>\n",
       "      <td>65.441</td>\n",
       "      <td>65.542</td>\n",
       "      <td>66.203</td>\n",
       "      <td>66.289</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>3.517</td>\n",
       "      <td>1.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>20</td>\n",
       "      <td>penn94</td>\n",
       "      <td>DecoupledFixedCompose</td>\n",
       "      <td>AdjDiffConv,AdjDiffConv-appr,appr</td>\n",
       "      <td>111</td>\n",
       "      <td>500</td>\n",
       "      <td>58.1150</td>\n",
       "      <td>3.006</td>\n",
       "      <td>1.393</td>\n",
       "      <td>86.051</td>\n",
       "      <td>86.178</td>\n",
       "      <td>75.013</td>\n",
       "      <td>75.216</td>\n",
       "      <td>75.237</td>\n",
       "      <td>75.564</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>3.006</td>\n",
       "      <td>1.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>21</td>\n",
       "      <td>penn94</td>\n",
       "      <td>DecoupledFixedCompose</td>\n",
       "      <td>AdjDiffConv,AdjDiffConv-appr,appr</td>\n",
       "      <td>107</td>\n",
       "      <td>500</td>\n",
       "      <td>55.9517</td>\n",
       "      <td>3.508</td>\n",
       "      <td>1.393</td>\n",
       "      <td>85.290</td>\n",
       "      <td>85.401</td>\n",
       "      <td>75.421</td>\n",
       "      <td>75.589</td>\n",
       "      <td>74.585</td>\n",
       "      <td>74.907</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>3.508</td>\n",
       "      <td>1.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>22</td>\n",
       "      <td>penn94</td>\n",
       "      <td>DecoupledFixedCompose</td>\n",
       "      <td>AdjDiffConv,AdjDiffConv-appr,appr</td>\n",
       "      <td>49</td>\n",
       "      <td>500</td>\n",
       "      <td>56.8672</td>\n",
       "      <td>3.526</td>\n",
       "      <td>1.393</td>\n",
       "      <td>79.103</td>\n",
       "      <td>79.355</td>\n",
       "      <td>75.118</td>\n",
       "      <td>75.499</td>\n",
       "      <td>74.872</td>\n",
       "      <td>75.151</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>3.526</td>\n",
       "      <td>1.393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seed    data                  model  \\\n",
       "0      20    cora              Iterative   \n",
       "1      21    cora              Iterative   \n",
       "2      22    cora              Iterative   \n",
       "3      20    cora              Iterative   \n",
       "4      21    cora              Iterative   \n",
       "..    ...     ...                    ...   \n",
       "895    21  penn94  DecoupledFixedCompose   \n",
       "896    22  penn94  DecoupledFixedCompose   \n",
       "897    20  penn94  DecoupledFixedCompose   \n",
       "898    21  penn94  DecoupledFixedCompose   \n",
       "899    22  penn94  DecoupledFixedCompose   \n",
       "\n",
       "                                      conv  epoch_best  epoch_learn  \\\n",
       "0                                  AdjConv          63          500   \n",
       "1                                  AdjConv          45          500   \n",
       "2                                  AdjConv          50          500   \n",
       "3                                 ChebConv          47          500   \n",
       "4                                 ChebConv          46          500   \n",
       "..                                     ...         ...          ...   \n",
       "895  Adji2Conv,Adji2Conv-gaussian,gaussian         287          500   \n",
       "896  Adji2Conv,Adji2Conv-gaussian,gaussian          37          500   \n",
       "897      AdjDiffConv,AdjDiffConv-appr,appr         111          500   \n",
       "898      AdjDiffConv,AdjDiffConv-appr,appr         107          500   \n",
       "899      AdjDiffConv,AdjDiffConv-appr,appr          49          500   \n",
       "\n",
       "     time_learn  mem_ram_train  mem_cuda_train  f1macro_train  f1micro_train  \\\n",
       "0        4.1765          1.080           0.059         92.248         93.169   \n",
       "1        4.0485          1.128           0.059         75.728         85.231   \n",
       "2        4.0349          1.132           0.059         76.519         85.908   \n",
       "3        6.4711          1.100           0.071         99.386         99.508   \n",
       "4        6.2731          1.147           0.071         98.865         99.077   \n",
       "..          ...            ...             ...            ...            ...   \n",
       "895    107.7445          3.517           1.861         81.109         81.124   \n",
       "896    106.8353          3.517           1.861         67.480         67.547   \n",
       "897     58.1150          3.006           1.393         86.051         86.178   \n",
       "898     55.9517          3.508           1.393         85.290         85.401   \n",
       "899     56.8672          3.526           1.393         79.103         79.355   \n",
       "\n",
       "     f1macro_val  f1micro_val  f1macro_test  f1micro_test  time_eval  \\\n",
       "0         88.792       90.037        87.530        89.094     0.0011   \n",
       "1         73.496       83.764        72.777        81.331     0.0011   \n",
       "2         70.762       79.705        76.251        86.876     0.0011   \n",
       "3         69.611       73.432        73.348        75.416     0.0017   \n",
       "4         72.122       75.461        73.184        75.231     0.0017   \n",
       "..           ...          ...           ...           ...        ...   \n",
       "895       77.627       77.638        76.942        76.981     0.0092   \n",
       "896       65.441       65.542        66.203        66.289     0.0093   \n",
       "897       75.013       75.216        75.237        75.564     0.0093   \n",
       "898       75.421       75.589        74.585        74.907     0.0085   \n",
       "899       75.118       75.499        74.872        75.151     0.0093   \n",
       "\n",
       "     mem_ram_eval  mem_cuda_eval  \n",
       "0           1.080          0.059  \n",
       "1           1.128          0.059  \n",
       "2           1.132          0.059  \n",
       "3           1.100          0.071  \n",
       "4           1.147          0.071  \n",
       "..            ...            ...  \n",
       "895         3.517          1.861  \n",
       "896         3.517          1.861  \n",
       "897         3.006          1.393  \n",
       "898         3.508          1.393  \n",
       "899         3.526          1.393  \n",
       "\n",
       "[900 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = LOGPATH.joinpath('summary-fb.csv')\n",
    "tori = pd.read_csv(fpath, engine='python')\n",
    "tori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>conv</th>\n",
       "      <th>epoch_learn</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>mem_ram_train</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>f1micro_test</th>\n",
       "      <th>time_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seed, data, model, conv, epoch_learn, time_learn, mem_ram_train, mem_cuda_train, f1micro_test, time_eval]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlst = [\"cora\", \"citeseer\", \"pubmed\", \"flickr\", \"chameleon_filtered\", \"squirrel_filtered\", \"actor\", \"roman_empire\", \\\n",
    "        \"amazon_ratings\", \"minesweeper\", \"tolokers\", \"questions\", \"reddit\", \"penn94\"]\n",
    "id_cols = [\"seed\", 'data', 'model', 'conv',]\n",
    "m_cols = ['epoch_learn', 'time_learn', 'mem_ram_train', 'mem_cuda_train', 'f1micro_test', 'time_eval',]\n",
    "t = tori[tori['data'].isin(dlst)][id_cols+m_cols].sort_values(by=['data', 'model', 'conv', 'seed'])\n",
    "t.sort_index(ascending=False).groupby(['data', 'model', 'conv']).filter(lambda x: len(x) > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>name</th>\n",
       "      <th>time_learn_mean</th>\n",
       "      <th>time_learn_std</th>\n",
       "      <th>mem_ram_train_mean</th>\n",
       "      <th>mem_ram_train_std</th>\n",
       "      <th>mem_cuda_train_mean</th>\n",
       "      <th>mem_cuda_train_std</th>\n",
       "      <th>f1micro_test_mean</th>\n",
       "      <th>f1micro_test_std</th>\n",
       "      <th>time_eval_mean</th>\n",
       "      <th>time_eval_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actor</td>\n",
       "      <td>ACMGNN</td>\n",
       "      <td>42.606200</td>\n",
       "      <td>1.100886</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>0.058847</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.675667</td>\n",
       "      <td>2.957597</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.264575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor</td>\n",
       "      <td>AdaGNN</td>\n",
       "      <td>10.009533</td>\n",
       "      <td>1.578104</td>\n",
       "      <td>1.170667</td>\n",
       "      <td>0.049075</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.070333</td>\n",
       "      <td>0.833196</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>0.115470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actor</td>\n",
       "      <td>PPR</td>\n",
       "      <td>9.703267</td>\n",
       "      <td>0.443809</td>\n",
       "      <td>1.130667</td>\n",
       "      <td>0.049075</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.236667</td>\n",
       "      <td>0.840125</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.173205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actor</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>9.855933</td>\n",
       "      <td>1.504255</td>\n",
       "      <td>1.151667</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.763333</td>\n",
       "      <td>0.174053</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>actor</td>\n",
       "      <td>HK</td>\n",
       "      <td>9.421800</td>\n",
       "      <td>1.131418</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.050269</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.679667</td>\n",
       "      <td>0.665349</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.173205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tolokers</td>\n",
       "      <td>ChebInterp</td>\n",
       "      <td>59.358267</td>\n",
       "      <td>1.791183</td>\n",
       "      <td>1.199667</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.235667</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>79.129333</td>\n",
       "      <td>0.673138</td>\n",
       "      <td>9.633333</td>\n",
       "      <td>1.365040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tolokers</td>\n",
       "      <td>Clenhaw</td>\n",
       "      <td>25.748867</td>\n",
       "      <td>2.445461</td>\n",
       "      <td>1.215333</td>\n",
       "      <td>0.071143</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.576667</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.057735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tolokers</td>\n",
       "      <td>Horner</td>\n",
       "      <td>27.344933</td>\n",
       "      <td>2.159201</td>\n",
       "      <td>1.192667</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.228667</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>78.236333</td>\n",
       "      <td>0.619582</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.152753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tolokers</td>\n",
       "      <td>FiGURe</td>\n",
       "      <td>169.319467</td>\n",
       "      <td>5.167309</td>\n",
       "      <td>1.213667</td>\n",
       "      <td>0.069759</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.137000</td>\n",
       "      <td>0.449778</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>0.435890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tolokers</td>\n",
       "      <td>Identity</td>\n",
       "      <td>3.601533</td>\n",
       "      <td>1.109408</td>\n",
       "      <td>1.151333</td>\n",
       "      <td>0.065241</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.321333</td>\n",
       "      <td>0.580410</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         data        name  time_learn_mean  time_learn_std  \\\n",
       "3       actor      ACMGNN        42.606200        1.100886   \n",
       "4       actor      AdaGNN        10.009533        1.578104   \n",
       "5       actor         PPR         9.703267        0.443809   \n",
       "6       actor    Gaussian         9.855933        1.504255   \n",
       "7       actor          HK         9.421800        1.131418   \n",
       "..        ...         ...              ...             ...   \n",
       "285  tolokers  ChebInterp        59.358267        1.791183   \n",
       "286  tolokers     Clenhaw        25.748867        2.445461   \n",
       "287  tolokers      Horner        27.344933        2.159201   \n",
       "288  tolokers      FiGURe       169.319467        5.167309   \n",
       "289  tolokers    Identity         3.601533        1.109408   \n",
       "\n",
       "     mem_ram_train_mean  mem_ram_train_std  mem_cuda_train_mean  \\\n",
       "3              1.230000           0.058847             0.413000   \n",
       "4              1.170667           0.049075             0.141000   \n",
       "5              1.130667           0.049075             0.108000   \n",
       "6              1.151667           0.057274             0.109000   \n",
       "7              1.120000           0.050269             0.108000   \n",
       "..                  ...                ...                  ...   \n",
       "285            1.199667           0.069400             0.235667   \n",
       "286            1.215333           0.071143             0.234000   \n",
       "287            1.192667           0.062164             0.228667   \n",
       "288            1.213667           0.069759             1.082000   \n",
       "289            1.151333           0.065241             0.069000   \n",
       "\n",
       "     mem_cuda_train_std  f1micro_test_mean  f1micro_test_std  time_eval_mean  \\\n",
       "3              0.000000          32.675667          2.957597        7.400000   \n",
       "4              0.000000          38.070333          0.833196        1.466667   \n",
       "5              0.000000          37.236667          0.840125        1.300000   \n",
       "6              0.000000          37.763333          0.174053        1.400000   \n",
       "7              0.000000          35.679667          0.665349        1.100000   \n",
       "..                  ...                ...               ...             ...   \n",
       "285            0.000577          79.129333          0.673138        9.633333   \n",
       "286            0.000000          78.576667          0.780269        3.166667   \n",
       "287            0.000577          78.236333          0.619582        2.966667   \n",
       "288            0.000000          78.137000          0.449778       43.800000   \n",
       "289            0.000000          78.321333          0.580410        0.600000   \n",
       "\n",
       "     time_eval_std  \n",
       "3         0.264575  \n",
       "4         0.115470  \n",
       "5         0.173205  \n",
       "6         0.200000  \n",
       "7         0.173205  \n",
       "..             ...  \n",
       "285       1.365040  \n",
       "286       0.057735  \n",
       "287       0.152753  \n",
       "288       0.435890  \n",
       "289       0.100000  \n",
       "\n",
       "[252 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_repr = {\n",
    "    'MLP': {\n",
    "        'Identity': 'Identity',\n",
    "    },\n",
    "    'DecoupledFixed': {\n",
    "        'AdjConv-impulse':  'Impulse',\n",
    "        'AdjConv-mono':     'Monomial',\n",
    "        'AdjConv-appr':     'PPR',\n",
    "        'AdjConv-hk':       'HK',\n",
    "        'AdjConv-gaussian': 'Gaussian',\n",
    "    },\n",
    "    'DecoupledVar': {\n",
    "        'AdjConv':          'Var-Monomial',\n",
    "        'HornerConv':       'Horner',\n",
    "        'ChebConv':         'Chebyshev',\n",
    "        'ChebConv2':        'ChebInterp',\n",
    "        'ClenhawConv':      'Clenshaw',\n",
    "        'BernConv':         'Bernstein',\n",
    "    },\n",
    "    'AdaGNN': {'AdaConv':   'AdaGNN'},\n",
    "    'ACMGNN': {\n",
    "        # 'ACMConv-1.0-low-high':     'FBGNNI',\n",
    "        # 'ACMConv-2.0-low-high':     'FBGNNII',\n",
    "        # 'ACMConv-1.0-low-high-id':  'ACMGNNI',\n",
    "        # 'ACMConv-2.0-low-high-id':  'ACMGNNII',\n",
    "        'ACMConv-2.0-low-high-id':  'ACMGNN',\n",
    "    },\n",
    "    'DecoupledFixedCompose': {\n",
    "        'AdjiConv,AdjiConv-mono,mono': 'FAGNN',\n",
    "        'Adji2Conv,Adji2Conv-gaussian,gaussian': 'G$^2$CN',\n",
    "        'AdjDiffConv,AdjDiffConv-appr,appr': 'GNN-LF/HF',\n",
    "    },\n",
    "    'DecoupledVarCompose': {\n",
    "        'AdjConv,ChebConv,BernConv': 'FiGURe',\n",
    "    }\n",
    "}\n",
    "flst = []\n",
    "for m in conv_repr.values():\n",
    "    for c, name in m.items():\n",
    "        flst.append(name)\n",
    "\n",
    "df = t.groupby(['data', 'model', 'conv'])[m_cols].agg(['mean', 'std'])\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "df['time_learn_mean'] = df['time_learn_mean'] * 1000 / df['epoch_learn_mean']\n",
    "df['time_learn_std'] = df['time_learn_std'] * 1000 / df['epoch_learn_mean']\n",
    "df['time_eval_mean'] = df['time_eval_mean'] * 1000\n",
    "df['time_eval_std'] = df['time_eval_std'] * 1000\n",
    "df.drop(columns=['epoch_learn_mean', 'epoch_learn_std'], inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df['name'] = df.apply(lambda row: conv_repr[row['model']][row['conv']] if (row['model'] in conv_repr) and (row['conv'] in conv_repr[row['model']]) else None, axis=1)\n",
    "df.dropna(subset=['name'], inplace=True)\n",
    "df.drop(columns=['model', 'conv'], inplace=True)\n",
    "df = df[['data', 'name'] + df.columns.tolist()[1:-1]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex - Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def calc_ranks(mean, std, ascending=False, exc=[]):\n",
    "    rank = pd.Series(np.nan, index=mean.index)\n",
    "    na_indices = mean[mean.isna()].index\n",
    "    nrows = len(mean)\n",
    "    rank[na_indices] = nrows\n",
    "\n",
    "    mean = mean.dropna()\n",
    "    mean = mean[~mean.index.isin(exc)]\n",
    "    std = std.loc[mean.index]\n",
    "    idx_pend = mean.sort_values(ascending=ascending).index\n",
    "    current_rank = 1\n",
    "    while not idx_pend.empty and current_rank <= nrows:\n",
    "        idx_top = idx_pend[0]\n",
    "        top_mean = mean[idx_top]\n",
    "        top_std = std[idx_top]\n",
    "        rank[idx_top] = current_rank\n",
    "\n",
    "        if ascending:\n",
    "            idx_same = idx_pend[mean[idx_pend] <= top_mean + top_std]\n",
    "        else:\n",
    "            idx_same = idx_pend[mean[idx_pend] >= top_mean - top_std]\n",
    "        rank[idx_same] = current_rank\n",
    "\n",
    "        idx_pend = idx_pend.difference(idx_same)\n",
    "        idx_pend = mean.loc[idx_pend].sort_values(ascending=ascending).index\n",
    "        current_rank += len(idx_same)\n",
    "\n",
    "    return rank\n",
    "\n",
    "rk = ['a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>flickr</th>\n",
       "      <th>chameleon_filtered</th>\n",
       "      <th>squirrel_filtered</th>\n",
       "      <th>actor</th>\n",
       "      <th>roman_empire</th>\n",
       "      <th>amazon_ratings</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>tolokers</th>\n",
       "      <th>questions</th>\n",
       "      <th>reddit</th>\n",
       "      <th>penn94</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Identity</th>\n",
       "      <td>75.17\\tpm{1.36}</td>\n",
       "      <td>72.93\\tpm{0.35}</td>\n",
       "      <td>87.81\\tpm{0.37}</td>\n",
       "      <td>35.46\\tpm{0.17}</td>\n",
       "      <td>30.52\\tpm{1.81}</td>\n",
       "      <td>32.13\\tpm{4.23}</td>\n",
       "      <td>37.02\\tpm{0.50}</td>\n",
       "      <td>65.30\\tpm{0.64}</td>\n",
       "      <td>43.29\\tpm{1.21}</td>\n",
       "      <td>80.53\\tpm{0.87}</td>\n",
       "      <td>78.32\\tpm{0.58}</td>\n",
       "      <td>96.93\\tpm{0.17}</td>\n",
       "      <td>36.91\\tpm{0.91}</td>\n",
       "      <td>74.61\\tpm{0.50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impulse</th>\n",
       "      <td>86.20\\tpm{1.55}</td>\n",
       "      <td>75.27\\tpm{0.26}</td>\n",
       "      <td>83.12\\tpm{0.83}</td>\n",
       "      <td>23.49\\tpm{3.96}</td>\n",
       "      <td>36.52\\tpm{3.93}</td>\n",
       "      <td>34.83\\tpm{1.50}</td>\n",
       "      <td>25.44\\tpm{0.72}</td>\n",
       "      <td>28.22\\tpm{0.80}</td>\n",
       "      <td>43.34\\tpm{0.51}</td>\n",
       "      <td>80.20\\tpm{0.70}</td>\n",
       "      <td>78.73\\tpm{0.59}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>23.71\\tpm{3.60}</td>\n",
       "      <td>56.61\\tpm{0.70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monomial</th>\n",
       "      <td>\\rkb{88.85\\tpm{1.19}}</td>\n",
       "      <td>77.00\\tpm{0.98}</td>\n",
       "      <td>89.37\\tpm{0.34}</td>\n",
       "      <td>\\rkb{37.41\\tpm{0.63}}</td>\n",
       "      <td>32.40\\tpm{2.53}</td>\n",
       "      <td>34.99\\tpm{3.12}</td>\n",
       "      <td>28.18\\tpm{8.12}</td>\n",
       "      <td>64.85\\tpm{0.89}</td>\n",
       "      <td>41.64\\tpm{0.50}</td>\n",
       "      <td>77.28\\tpm{5.05}</td>\n",
       "      <td>78.70\\tpm{0.90}</td>\n",
       "      <td>96.97\\tpm{0.06}</td>\n",
       "      <td>36.45\\tpm{0.86}</td>\n",
       "      <td>75.85\\tpm{0.30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPR</th>\n",
       "      <td>\\rka{89.09\\tpm{1.82}}</td>\n",
       "      <td>77.10\\tpm{0.46}</td>\n",
       "      <td>88.94\\tpm{0.52}</td>\n",
       "      <td>36.62\\tpm{0.44}</td>\n",
       "      <td>35.21\\tpm{2.34}</td>\n",
       "      <td>35.89\\tpm{3.94}</td>\n",
       "      <td>37.24\\tpm{0.84}</td>\n",
       "      <td>65.48\\tpm{1.26}</td>\n",
       "      <td>\\rkc{43.97\\tpm{0.81}}</td>\n",
       "      <td>80.53\\tpm{0.87}</td>\n",
       "      <td>78.25\\tpm{0.60}</td>\n",
       "      <td>94.35\\tpm{4.48}</td>\n",
       "      <td>36.03\\tpm{0.82}</td>\n",
       "      <td>74.97\\tpm{0.17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HK</th>\n",
       "      <td>86.81\\tpm{3.89}</td>\n",
       "      <td>77.15\\tpm{1.04}</td>\n",
       "      <td>89.34\\tpm{0.11}</td>\n",
       "      <td>36.18\\tpm{1.03}</td>\n",
       "      <td>32.02\\tpm{1.49}</td>\n",
       "      <td>32.96\\tpm{1.69}</td>\n",
       "      <td>35.68\\tpm{0.67}</td>\n",
       "      <td>64.64\\tpm{0.24}</td>\n",
       "      <td>41.98\\tpm{0.21}</td>\n",
       "      <td>80.50\\tpm{0.74}</td>\n",
       "      <td>\\rkb{78.92\\tpm{0.79}}</td>\n",
       "      <td>96.95\\tpm{0.06}</td>\n",
       "      <td>35.68\\tpm{0.70}</td>\n",
       "      <td>63.48\\tpm{10.13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>88.36\\tpm{1.78}</td>\n",
       "      <td>77.15\\tpm{0.89}</td>\n",
       "      <td>89.03\\tpm{0.26}</td>\n",
       "      <td>35.64\\tpm{1.62}</td>\n",
       "      <td>35.21\\tpm{1.30}</td>\n",
       "      <td>36.19\\tpm{1.97}</td>\n",
       "      <td>37.76\\tpm{0.17}</td>\n",
       "      <td>\\rkc{66.41\\tpm{1.00}}</td>\n",
       "      <td>43.38\\tpm{1.14}</td>\n",
       "      <td>81.00\\tpm{1.61}</td>\n",
       "      <td>78.34\\tpm{0.59}</td>\n",
       "      <td>\\rkb{96.98\\tpm{0.08}}</td>\n",
       "      <td>37.08\\tpm{0.46}</td>\n",
       "      <td>75.56\\tpm{0.17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var-Monomial</th>\n",
       "      <td>85.46\\tpm{5.07}</td>\n",
       "      <td>\\rkc{77.25\\tpm{0.67}}</td>\n",
       "      <td>88.38\\tpm{0.35}</td>\n",
       "      <td>\\rkc{37.22\\tpm{0.78}}</td>\n",
       "      <td>35.21\\tpm{2.27}</td>\n",
       "      <td>\\rka{40.99\\tpm{1.84}}</td>\n",
       "      <td>36.51\\tpm{0.87}</td>\n",
       "      <td>65.67\\tpm{2.13}</td>\n",
       "      <td>42.75\\tpm{0.53}</td>\n",
       "      <td>79.48\\tpm{3.62}</td>\n",
       "      <td>78.59\\tpm{0.69}</td>\n",
       "      <td>\\rkc{96.97\\tpm{0.07}}</td>\n",
       "      <td>36.32\\tpm{1.60}</td>\n",
       "      <td>78.95\\tpm{2.89}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horner</th>\n",
       "      <td>87.49\\tpm{0.91}</td>\n",
       "      <td>75.42\\tpm{2.38}</td>\n",
       "      <td>\\rkc{89.69\\tpm{0.62}}</td>\n",
       "      <td>35.20\\tpm{1.14}</td>\n",
       "      <td>35.39\\tpm{4.46}</td>\n",
       "      <td>32.21\\tpm{2.17}</td>\n",
       "      <td>37.76\\tpm{0.70}</td>\n",
       "      <td>\\rka{67.39\\tpm{1.53}}</td>\n",
       "      <td>41.67\\tpm{0.91}</td>\n",
       "      <td>\\rkb{85.48\\tpm{0.42}}</td>\n",
       "      <td>78.24\\tpm{0.62}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>\\rkc{37.32\\tpm{0.44}}</td>\n",
       "      <td>80.17\\tpm{3.48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chebyshev</th>\n",
       "      <td>73.81\\tpm{1.26}</td>\n",
       "      <td>71.40\\tpm{0.54}</td>\n",
       "      <td>88.53\\tpm{0.52}</td>\n",
       "      <td>35.90\\tpm{0.33}</td>\n",
       "      <td>35.58\\tpm{3.19}</td>\n",
       "      <td>37.09\\tpm{2.49}</td>\n",
       "      <td>37.87\\tpm{0.76}</td>\n",
       "      <td>64.92\\tpm{0.57}</td>\n",
       "      <td>40.17\\tpm{2.03}</td>\n",
       "      <td>75.28\\tpm{0.52}</td>\n",
       "      <td>78.24\\tpm{0.62}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>37.24\\tpm{0.46}</td>\n",
       "      <td>75.54\\tpm{0.41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChebInterp</th>\n",
       "      <td>82.13\\tpm{4.68}</td>\n",
       "      <td>76.49\\tpm{0.55}</td>\n",
       "      <td>\\rka{90.03\\tpm{0.41}}</td>\n",
       "      <td>32.24\\tpm{3.37}</td>\n",
       "      <td>\\rka{40.82\\tpm{1.17}}</td>\n",
       "      <td>36.71\\tpm{1.41}</td>\n",
       "      <td>31.93\\tpm{7.55}</td>\n",
       "      <td>65.63\\tpm{0.81}</td>\n",
       "      <td>\\rka{45.03\\tpm{0.40}}</td>\n",
       "      <td>81.37\\tpm{1.08}</td>\n",
       "      <td>\\rka{79.13\\tpm{0.67}}</td>\n",
       "      <td>\\rka{97.03\\tpm{0.07}}</td>\n",
       "      <td>31.40\\tpm{4.18}</td>\n",
       "      <td>73.72\\tpm{15.51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clenhaw</th>\n",
       "      <td>86.20\\tpm{0.77}</td>\n",
       "      <td>72.98\\tpm{7.28}</td>\n",
       "      <td>78.04\\tpm{19.26}</td>\n",
       "      <td>28.73\\tpm{4.31}</td>\n",
       "      <td>30.90\\tpm{6.81}</td>\n",
       "      <td>32.73\\tpm{2.94}</td>\n",
       "      <td>\\rkc{38.03\\tpm{1.20}}</td>\n",
       "      <td>65.92\\tpm{1.98}</td>\n",
       "      <td>\\rkb{44.07\\tpm{0.08}}</td>\n",
       "      <td>\\rkc{85.18\\tpm{0.58}}</td>\n",
       "      <td>78.58\\tpm{0.78}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>37.13\\tpm{1.85}</td>\n",
       "      <td>\\rka{83.41\\tpm{0.76}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernstein</th>\n",
       "      <td>74.37\\tpm{0.85}</td>\n",
       "      <td>57.86\\tpm{22.35}</td>\n",
       "      <td>76.97\\tpm{17.77}</td>\n",
       "      <td>34.17\\tpm{0.08}</td>\n",
       "      <td>\\rkc{36.70\\tpm{3.24}}</td>\n",
       "      <td>35.36\\tpm{3.25}</td>\n",
       "      <td>37.17\\tpm{1.26}</td>\n",
       "      <td>61.91\\tpm{1.59}</td>\n",
       "      <td>37.36\\tpm{1.23}</td>\n",
       "      <td>78.30\\tpm{4.76}</td>\n",
       "      <td>78.52\\tpm{0.48}</td>\n",
       "      <td>96.64\\tpm{0.33}</td>\n",
       "      <td>\\rkb{37.65\\tpm{0.88}}</td>\n",
       "      <td>77.75\\tpm{0.61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaGNN</th>\n",
       "      <td>88.60\\tpm{0.95}</td>\n",
       "      <td>76.69\\tpm{1.17}</td>\n",
       "      <td>89.66\\tpm{0.32}</td>\n",
       "      <td>\\rka{37.41\\tpm{1.81}}</td>\n",
       "      <td>35.58\\tpm{1.72}</td>\n",
       "      <td>36.11\\tpm{2.69}</td>\n",
       "      <td>\\rka{38.07\\tpm{0.83}}</td>\n",
       "      <td>\\rkb{66.73\\tpm{1.69}}</td>\n",
       "      <td>43.45\\tpm{2.62}</td>\n",
       "      <td>82.37\\tpm{0.98}</td>\n",
       "      <td>78.24\\tpm{0.65}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>\\rka{38.36\\tpm{0.80}}</td>\n",
       "      <td>\\rkc{81.87\\tpm{0.11}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACMGNN</th>\n",
       "      <td>71.66\\tpm{1.72}</td>\n",
       "      <td>38.32\\tpm{4.20}</td>\n",
       "      <td>87.96\\tpm{0.76}</td>\n",
       "      <td>31.36\\tpm{0.51}</td>\n",
       "      <td>31.84\\tpm{4.14}</td>\n",
       "      <td>\\rkc{37.84\\tpm{2.29}}</td>\n",
       "      <td>32.68\\tpm{2.96}</td>\n",
       "      <td>64.02\\tpm{6.26}</td>\n",
       "      <td>40.36\\tpm{1.10}</td>\n",
       "      <td>\\rka{90.00\\tpm{0.82}}</td>\n",
       "      <td>78.51\\tpm{0.31}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>29.30\\tpm{4.09}</td>\n",
       "      <td>69.61\\tpm{1.87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAGNN</th>\n",
       "      <td>88.29\\tpm{1.07}</td>\n",
       "      <td>74.71\\tpm{0.44}</td>\n",
       "      <td>83.77\\tpm{0.59}</td>\n",
       "      <td>25.92\\tpm{1.27}</td>\n",
       "      <td>36.33\\tpm{1.81}</td>\n",
       "      <td>34.68\\tpm{2.06}</td>\n",
       "      <td>24.61\\tpm{1.45}</td>\n",
       "      <td>28.82\\tpm{0.75}</td>\n",
       "      <td>42.57\\tpm{0.32}</td>\n",
       "      <td>71.00\\tpm{13.74}</td>\n",
       "      <td>\\rkc{78.79\\tpm{0.54}}</td>\n",
       "      <td>96.95\\tpm{0.04}</td>\n",
       "      <td>24.08\\tpm{1.03}</td>\n",
       "      <td>55.30\\tpm{2.81}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G$^2$CN</th>\n",
       "      <td>82.25\\tpm{3.11}</td>\n",
       "      <td>\\rkb{77.40\\tpm{0.67}}</td>\n",
       "      <td>88.27\\tpm{0.39}</td>\n",
       "      <td>24.56\\tpm{0.27}</td>\n",
       "      <td>30.52\\tpm{0.65}</td>\n",
       "      <td>33.71\\tpm{2.48}</td>\n",
       "      <td>34.80\\tpm{1.34}</td>\n",
       "      <td>49.25\\tpm{0.51}</td>\n",
       "      <td>42.98\\tpm{1.15}</td>\n",
       "      <td>80.45\\tpm{0.98}</td>\n",
       "      <td>78.62\\tpm{0.81}</td>\n",
       "      <td>96.97\\tpm{0.04}</td>\n",
       "      <td>35.66\\tpm{0.66}</td>\n",
       "      <td>65.46\\tpm{11.96}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNN-LF/HF</th>\n",
       "      <td>85.71\\tpm{0.59}</td>\n",
       "      <td>74.86\\tpm{0.38}</td>\n",
       "      <td>88.60\\tpm{0.83}</td>\n",
       "      <td>37.15\\tpm{1.55}</td>\n",
       "      <td>34.83\\tpm{3.13}</td>\n",
       "      <td>21.55\\tpm{2.19}</td>\n",
       "      <td>35.00\\tpm{1.66}</td>\n",
       "      <td>64.01\\tpm{0.33}</td>\n",
       "      <td>41.47\\tpm{0.69}</td>\n",
       "      <td>79.20\\tpm{3.17}</td>\n",
       "      <td>78.21\\tpm{0.61}</td>\n",
       "      <td>96.95\\tpm{0.03}</td>\n",
       "      <td>35.77\\tpm{0.94}</td>\n",
       "      <td>75.21\\tpm{0.33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiGURe</th>\n",
       "      <td>\\rkc{88.60\\tpm{0.28}}</td>\n",
       "      <td>\\rka{77.96\\tpm{0.64}}</td>\n",
       "      <td>\\rkb{89.70\\tpm{0.16}}</td>\n",
       "      <td>35.35\\tpm{0.94}</td>\n",
       "      <td>\\rkb{36.70\\tpm{1.81}}</td>\n",
       "      <td>\\rkb{39.49\\tpm{0.57}}</td>\n",
       "      <td>\\rkb{38.05\\tpm{0.99}}</td>\n",
       "      <td>64.28\\tpm{2.61}</td>\n",
       "      <td>42.63\\tpm{0.79}</td>\n",
       "      <td>80.85\\tpm{0.93}</td>\n",
       "      <td>78.14\\tpm{0.45}</td>\n",
       "      <td>96.96\\tpm{0.03}</td>\n",
       "      <td>35.75\\tpm{1.46}</td>\n",
       "      <td>\\rkb{83.31\\tpm{0.36}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               cora               citeseer  \\\n",
       "Identity            75.17\\tpm{1.36}        72.93\\tpm{0.35}   \n",
       "Impulse             86.20\\tpm{1.55}        75.27\\tpm{0.26}   \n",
       "Monomial      \\rkb{88.85\\tpm{1.19}}        77.00\\tpm{0.98}   \n",
       "PPR           \\rka{89.09\\tpm{1.82}}        77.10\\tpm{0.46}   \n",
       "HK                  86.81\\tpm{3.89}        77.15\\tpm{1.04}   \n",
       "Gaussian            88.36\\tpm{1.78}        77.15\\tpm{0.89}   \n",
       "Var-Monomial        85.46\\tpm{5.07}  \\rkc{77.25\\tpm{0.67}}   \n",
       "Horner              87.49\\tpm{0.91}        75.42\\tpm{2.38}   \n",
       "Chebyshev           73.81\\tpm{1.26}        71.40\\tpm{0.54}   \n",
       "ChebInterp          82.13\\tpm{4.68}        76.49\\tpm{0.55}   \n",
       "Clenhaw             86.20\\tpm{0.77}        72.98\\tpm{7.28}   \n",
       "Bernstein           74.37\\tpm{0.85}       57.86\\tpm{22.35}   \n",
       "AdaGNN              88.60\\tpm{0.95}        76.69\\tpm{1.17}   \n",
       "ACMGNN              71.66\\tpm{1.72}        38.32\\tpm{4.20}   \n",
       "FAGNN               88.29\\tpm{1.07}        74.71\\tpm{0.44}   \n",
       "G$^2$CN             82.25\\tpm{3.11}  \\rkb{77.40\\tpm{0.67}}   \n",
       "GNN-LF/HF           85.71\\tpm{0.59}        74.86\\tpm{0.38}   \n",
       "FiGURe        \\rkc{88.60\\tpm{0.28}}  \\rka{77.96\\tpm{0.64}}   \n",
       "\n",
       "                             pubmed                 flickr  \\\n",
       "Identity            87.81\\tpm{0.37}        35.46\\tpm{0.17}   \n",
       "Impulse             83.12\\tpm{0.83}        23.49\\tpm{3.96}   \n",
       "Monomial            89.37\\tpm{0.34}  \\rkb{37.41\\tpm{0.63}}   \n",
       "PPR                 88.94\\tpm{0.52}        36.62\\tpm{0.44}   \n",
       "HK                  89.34\\tpm{0.11}        36.18\\tpm{1.03}   \n",
       "Gaussian            89.03\\tpm{0.26}        35.64\\tpm{1.62}   \n",
       "Var-Monomial        88.38\\tpm{0.35}  \\rkc{37.22\\tpm{0.78}}   \n",
       "Horner        \\rkc{89.69\\tpm{0.62}}        35.20\\tpm{1.14}   \n",
       "Chebyshev           88.53\\tpm{0.52}        35.90\\tpm{0.33}   \n",
       "ChebInterp    \\rka{90.03\\tpm{0.41}}        32.24\\tpm{3.37}   \n",
       "Clenhaw            78.04\\tpm{19.26}        28.73\\tpm{4.31}   \n",
       "Bernstein          76.97\\tpm{17.77}        34.17\\tpm{0.08}   \n",
       "AdaGNN              89.66\\tpm{0.32}  \\rka{37.41\\tpm{1.81}}   \n",
       "ACMGNN              87.96\\tpm{0.76}        31.36\\tpm{0.51}   \n",
       "FAGNN               83.77\\tpm{0.59}        25.92\\tpm{1.27}   \n",
       "G$^2$CN             88.27\\tpm{0.39}        24.56\\tpm{0.27}   \n",
       "GNN-LF/HF           88.60\\tpm{0.83}        37.15\\tpm{1.55}   \n",
       "FiGURe        \\rkb{89.70\\tpm{0.16}}        35.35\\tpm{0.94}   \n",
       "\n",
       "                 chameleon_filtered      squirrel_filtered  \\\n",
       "Identity            30.52\\tpm{1.81}        32.13\\tpm{4.23}   \n",
       "Impulse             36.52\\tpm{3.93}        34.83\\tpm{1.50}   \n",
       "Monomial            32.40\\tpm{2.53}        34.99\\tpm{3.12}   \n",
       "PPR                 35.21\\tpm{2.34}        35.89\\tpm{3.94}   \n",
       "HK                  32.02\\tpm{1.49}        32.96\\tpm{1.69}   \n",
       "Gaussian            35.21\\tpm{1.30}        36.19\\tpm{1.97}   \n",
       "Var-Monomial        35.21\\tpm{2.27}  \\rka{40.99\\tpm{1.84}}   \n",
       "Horner              35.39\\tpm{4.46}        32.21\\tpm{2.17}   \n",
       "Chebyshev           35.58\\tpm{3.19}        37.09\\tpm{2.49}   \n",
       "ChebInterp    \\rka{40.82\\tpm{1.17}}        36.71\\tpm{1.41}   \n",
       "Clenhaw             30.90\\tpm{6.81}        32.73\\tpm{2.94}   \n",
       "Bernstein     \\rkc{36.70\\tpm{3.24}}        35.36\\tpm{3.25}   \n",
       "AdaGNN              35.58\\tpm{1.72}        36.11\\tpm{2.69}   \n",
       "ACMGNN              31.84\\tpm{4.14}  \\rkc{37.84\\tpm{2.29}}   \n",
       "FAGNN               36.33\\tpm{1.81}        34.68\\tpm{2.06}   \n",
       "G$^2$CN             30.52\\tpm{0.65}        33.71\\tpm{2.48}   \n",
       "GNN-LF/HF           34.83\\tpm{3.13}        21.55\\tpm{2.19}   \n",
       "FiGURe        \\rkb{36.70\\tpm{1.81}}  \\rkb{39.49\\tpm{0.57}}   \n",
       "\n",
       "                              actor           roman_empire  \\\n",
       "Identity            37.02\\tpm{0.50}        65.30\\tpm{0.64}   \n",
       "Impulse             25.44\\tpm{0.72}        28.22\\tpm{0.80}   \n",
       "Monomial            28.18\\tpm{8.12}        64.85\\tpm{0.89}   \n",
       "PPR                 37.24\\tpm{0.84}        65.48\\tpm{1.26}   \n",
       "HK                  35.68\\tpm{0.67}        64.64\\tpm{0.24}   \n",
       "Gaussian            37.76\\tpm{0.17}  \\rkc{66.41\\tpm{1.00}}   \n",
       "Var-Monomial        36.51\\tpm{0.87}        65.67\\tpm{2.13}   \n",
       "Horner              37.76\\tpm{0.70}  \\rka{67.39\\tpm{1.53}}   \n",
       "Chebyshev           37.87\\tpm{0.76}        64.92\\tpm{0.57}   \n",
       "ChebInterp          31.93\\tpm{7.55}        65.63\\tpm{0.81}   \n",
       "Clenhaw       \\rkc{38.03\\tpm{1.20}}        65.92\\tpm{1.98}   \n",
       "Bernstein           37.17\\tpm{1.26}        61.91\\tpm{1.59}   \n",
       "AdaGNN        \\rka{38.07\\tpm{0.83}}  \\rkb{66.73\\tpm{1.69}}   \n",
       "ACMGNN              32.68\\tpm{2.96}        64.02\\tpm{6.26}   \n",
       "FAGNN               24.61\\tpm{1.45}        28.82\\tpm{0.75}   \n",
       "G$^2$CN             34.80\\tpm{1.34}        49.25\\tpm{0.51}   \n",
       "GNN-LF/HF           35.00\\tpm{1.66}        64.01\\tpm{0.33}   \n",
       "FiGURe        \\rkb{38.05\\tpm{0.99}}        64.28\\tpm{2.61}   \n",
       "\n",
       "                     amazon_ratings            minesweeper  \\\n",
       "Identity            43.29\\tpm{1.21}        80.53\\tpm{0.87}   \n",
       "Impulse             43.34\\tpm{0.51}        80.20\\tpm{0.70}   \n",
       "Monomial            41.64\\tpm{0.50}        77.28\\tpm{5.05}   \n",
       "PPR           \\rkc{43.97\\tpm{0.81}}        80.53\\tpm{0.87}   \n",
       "HK                  41.98\\tpm{0.21}        80.50\\tpm{0.74}   \n",
       "Gaussian            43.38\\tpm{1.14}        81.00\\tpm{1.61}   \n",
       "Var-Monomial        42.75\\tpm{0.53}        79.48\\tpm{3.62}   \n",
       "Horner              41.67\\tpm{0.91}  \\rkb{85.48\\tpm{0.42}}   \n",
       "Chebyshev           40.17\\tpm{2.03}        75.28\\tpm{0.52}   \n",
       "ChebInterp    \\rka{45.03\\tpm{0.40}}        81.37\\tpm{1.08}   \n",
       "Clenhaw       \\rkb{44.07\\tpm{0.08}}  \\rkc{85.18\\tpm{0.58}}   \n",
       "Bernstein           37.36\\tpm{1.23}        78.30\\tpm{4.76}   \n",
       "AdaGNN              43.45\\tpm{2.62}        82.37\\tpm{0.98}   \n",
       "ACMGNN              40.36\\tpm{1.10}  \\rka{90.00\\tpm{0.82}}   \n",
       "FAGNN               42.57\\tpm{0.32}       71.00\\tpm{13.74}   \n",
       "G$^2$CN             42.98\\tpm{1.15}        80.45\\tpm{0.98}   \n",
       "GNN-LF/HF           41.47\\tpm{0.69}        79.20\\tpm{3.17}   \n",
       "FiGURe              42.63\\tpm{0.79}        80.85\\tpm{0.93}   \n",
       "\n",
       "                           tolokers              questions  \\\n",
       "Identity            78.32\\tpm{0.58}        96.93\\tpm{0.17}   \n",
       "Impulse             78.73\\tpm{0.59}        96.96\\tpm{0.03}   \n",
       "Monomial            78.70\\tpm{0.90}        96.97\\tpm{0.06}   \n",
       "PPR                 78.25\\tpm{0.60}        94.35\\tpm{4.48}   \n",
       "HK            \\rkb{78.92\\tpm{0.79}}        96.95\\tpm{0.06}   \n",
       "Gaussian            78.34\\tpm{0.59}  \\rkb{96.98\\tpm{0.08}}   \n",
       "Var-Monomial        78.59\\tpm{0.69}  \\rkc{96.97\\tpm{0.07}}   \n",
       "Horner              78.24\\tpm{0.62}        96.96\\tpm{0.03}   \n",
       "Chebyshev           78.24\\tpm{0.62}        96.96\\tpm{0.03}   \n",
       "ChebInterp    \\rka{79.13\\tpm{0.67}}  \\rka{97.03\\tpm{0.07}}   \n",
       "Clenhaw             78.58\\tpm{0.78}        96.96\\tpm{0.03}   \n",
       "Bernstein           78.52\\tpm{0.48}        96.64\\tpm{0.33}   \n",
       "AdaGNN              78.24\\tpm{0.65}        96.96\\tpm{0.03}   \n",
       "ACMGNN              78.51\\tpm{0.31}        96.96\\tpm{0.03}   \n",
       "FAGNN         \\rkc{78.79\\tpm{0.54}}        96.95\\tpm{0.04}   \n",
       "G$^2$CN             78.62\\tpm{0.81}        96.97\\tpm{0.04}   \n",
       "GNN-LF/HF           78.21\\tpm{0.61}        96.95\\tpm{0.03}   \n",
       "FiGURe              78.14\\tpm{0.45}        96.96\\tpm{0.03}   \n",
       "\n",
       "                             reddit                 penn94  \n",
       "Identity            36.91\\tpm{0.91}        74.61\\tpm{0.50}  \n",
       "Impulse             23.71\\tpm{3.60}        56.61\\tpm{0.70}  \n",
       "Monomial            36.45\\tpm{0.86}        75.85\\tpm{0.30}  \n",
       "PPR                 36.03\\tpm{0.82}        74.97\\tpm{0.17}  \n",
       "HK                  35.68\\tpm{0.70}       63.48\\tpm{10.13}  \n",
       "Gaussian            37.08\\tpm{0.46}        75.56\\tpm{0.17}  \n",
       "Var-Monomial        36.32\\tpm{1.60}        78.95\\tpm{2.89}  \n",
       "Horner        \\rkc{37.32\\tpm{0.44}}        80.17\\tpm{3.48}  \n",
       "Chebyshev           37.24\\tpm{0.46}        75.54\\tpm{0.41}  \n",
       "ChebInterp          31.40\\tpm{4.18}       73.72\\tpm{15.51}  \n",
       "Clenhaw             37.13\\tpm{1.85}  \\rka{83.41\\tpm{0.76}}  \n",
       "Bernstein     \\rkb{37.65\\tpm{0.88}}        77.75\\tpm{0.61}  \n",
       "AdaGNN        \\rka{38.36\\tpm{0.80}}  \\rkc{81.87\\tpm{0.11}}  \n",
       "ACMGNN              29.30\\tpm{4.09}        69.61\\tpm{1.87}  \n",
       "FAGNN               24.08\\tpm{1.03}        55.30\\tpm{2.81}  \n",
       "G$^2$CN             35.66\\tpm{0.66}       65.46\\tpm{11.96}  \n",
       "GNN-LF/HF           35.77\\tpm{0.94}        75.21\\tpm{0.33}  \n",
       "FiGURe              35.75\\tpm{1.46}  \\rkb{83.31\\tpm{0.36}}  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlst_acc = dlst\n",
    "# dlst_acc = [\"cora\", \"citeseer\", \"pubmed\", \"flickr\", \"chameleon_filtered\", \"squirrel_filtered\", \"actor\", \"roman_empire\"]\n",
    "acc_str = pd.DataFrame(index=flst, columns=dlst_acc, dtype=str)\n",
    "for row in acc_str.index:\n",
    "    for col in acc_str.columns:\n",
    "        mean = df.loc[(df['name'] == row) & (df['data'] == col), 'f1micro_test_mean'].values\n",
    "        std = df.loc[(df['name'] == row) & (df['data'] == col), 'f1micro_test_std'].values\n",
    "        if len(mean) > 0:\n",
    "            acc_str.loc[row, col] = f'{mean[0]:.2f}\\\\tpm{{{std[0]:.2f}}}'\n",
    "\n",
    "# acc_str[acc_str.isna().any(axis=1)]\n",
    "# acc_str.dropna(inplace=True)\n",
    "\n",
    "for col in acc_str.columns:\n",
    "    mean = df.loc[df['data'] == col, ['name', 'f1micro_test_mean']].set_index('name')['f1micro_test_mean'].astype(float)\n",
    "    std  = df.loc[df['data'] == col, ['name', 'f1micro_test_std']].set_index('name')['f1micro_test_std'].astype(float)\n",
    "    # rank = calc_ranks(mean, std)\n",
    "    rank = mean.rank(ascending=False).astype(int)\n",
    "    for i, rki in enumerate(rk):\n",
    "        idx = rank[rank == i+1].index\n",
    "        acc_str.loc[idx, col] = f'\\\\rk{rki}' + '{' + acc_str.loc[idx, col] + '}'\n",
    "\n",
    "acc_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t& Identity & 75.17\\tpm{1.36} & 72.93\\tpm{0.35} & 87.81\\tpm{0.37} & 35.46\\tpm{0.17} & 30.52\\tpm{1.81} & 32.13\\tpm{4.23} & 37.02\\tpm{0.50} & 65.30\\tpm{0.64} & 43.29\\tpm{1.21} & 80.53\\tpm{0.87} & 78.32\\tpm{0.58} & 96.93\\tpm{0.17} & 36.91\\tpm{0.91} & 74.61\\tpm{0.50} \\\\\n",
      "\t& Impulse & 86.20\\tpm{1.55} & 75.27\\tpm{0.26} & 83.12\\tpm{0.83} & 23.49\\tpm{3.96} & 36.52\\tpm{3.93} & 34.83\\tpm{1.50} & 25.44\\tpm{0.72} & 28.22\\tpm{0.80} & 43.34\\tpm{0.51} & 80.20\\tpm{0.70} & 78.73\\tpm{0.59} & 96.96\\tpm{0.03} & 23.71\\tpm{3.60} & 56.61\\tpm{0.70} \\\\\n",
      "\t& Monomial & \\rkb{88.85\\tpm{1.19}} & 77.00\\tpm{0.98} & 89.37\\tpm{0.34} & \\rkb{37.41\\tpm{0.63}} & 32.40\\tpm{2.53} & 34.99\\tpm{3.12} & 28.18\\tpm{8.12} & 64.85\\tpm{0.89} & 41.64\\tpm{0.50} & 77.28\\tpm{5.05} & 78.70\\tpm{0.90} & 96.97\\tpm{0.06} & 36.45\\tpm{0.86} & 75.85\\tpm{0.30} \\\\\n",
      "\t& PPR & \\rka{89.09\\tpm{1.82}} & 77.10\\tpm{0.46} & 88.94\\tpm{0.52} & 36.62\\tpm{0.44} & 35.21\\tpm{2.34} & 35.89\\tpm{3.94} & 37.24\\tpm{0.84} & 65.48\\tpm{1.26} & \\rkc{43.97\\tpm{0.81}} & 80.53\\tpm{0.87} & 78.25\\tpm{0.60} & 94.35\\tpm{4.48} & 36.03\\tpm{0.82} & 74.97\\tpm{0.17} \\\\\n",
      "\t& HK & 86.81\\tpm{3.89} & 77.15\\tpm{1.04} & 89.34\\tpm{0.11} & 36.18\\tpm{1.03} & 32.02\\tpm{1.49} & 32.96\\tpm{1.69} & 35.68\\tpm{0.67} & 64.64\\tpm{0.24} & 41.98\\tpm{0.21} & 80.50\\tpm{0.74} & \\rkb{78.92\\tpm{0.79}} & 96.95\\tpm{0.06} & 35.68\\tpm{0.70} & 63.48\\tpm{10.13} \\\\\n",
      "\t& Gaussian & 88.36\\tpm{1.78} & 77.15\\tpm{0.89} & 89.03\\tpm{0.26} & 35.64\\tpm{1.62} & 35.21\\tpm{1.30} & 36.19\\tpm{1.97} & 37.76\\tpm{0.17} & \\rkc{66.41\\tpm{1.00}} & 43.38\\tpm{1.14} & 81.00\\tpm{1.61} & 78.34\\tpm{0.59} & \\rkb{96.98\\tpm{0.08}} & 37.08\\tpm{0.46} & 75.56\\tpm{0.17} \\\\\n",
      "\t& Var-Monomial & 85.46\\tpm{5.07} & \\rkc{77.25\\tpm{0.67}} & 88.38\\tpm{0.35} & \\rkc{37.22\\tpm{0.78}} & 35.21\\tpm{2.27} & \\rka{40.99\\tpm{1.84}} & 36.51\\tpm{0.87} & 65.67\\tpm{2.13} & 42.75\\tpm{0.53} & 79.48\\tpm{3.62} & 78.59\\tpm{0.69} & \\rkc{96.97\\tpm{0.07}} & 36.32\\tpm{1.60} & 78.95\\tpm{2.89} \\\\\n",
      "\t& Horner & 87.49\\tpm{0.91} & 75.42\\tpm{2.38} & \\rkc{89.69\\tpm{0.62}} & 35.20\\tpm{1.14} & 35.39\\tpm{4.46} & 32.21\\tpm{2.17} & 37.76\\tpm{0.70} & \\rka{67.39\\tpm{1.53}} & 41.67\\tpm{0.91} & \\rkb{85.48\\tpm{0.42}} & 78.24\\tpm{0.62} & 96.96\\tpm{0.03} & \\rkc{37.32\\tpm{0.44}} & 80.17\\tpm{3.48} \\\\\n",
      "\t& Chebyshev & 73.81\\tpm{1.26} & 71.40\\tpm{0.54} & 88.53\\tpm{0.52} & 35.90\\tpm{0.33} & 35.58\\tpm{3.19} & 37.09\\tpm{2.49} & 37.87\\tpm{0.76} & 64.92\\tpm{0.57} & 40.17\\tpm{2.03} & 75.28\\tpm{0.52} & 78.24\\tpm{0.62} & 96.96\\tpm{0.03} & 37.24\\tpm{0.46} & 75.54\\tpm{0.41} \\\\\n",
      "\t& ChebInterp & 82.13\\tpm{4.68} & 76.49\\tpm{0.55} & \\rka{90.03\\tpm{0.41}} & 32.24\\tpm{3.37} & \\rka{40.82\\tpm{1.17}} & 36.71\\tpm{1.41} & 31.93\\tpm{7.55} & 65.63\\tpm{0.81} & \\rka{45.03\\tpm{0.40}} & 81.37\\tpm{1.08} & \\rka{79.13\\tpm{0.67}} & \\rka{97.03\\tpm{0.07}} & 31.40\\tpm{4.18} & 73.72\\tpm{15.51} \\\\\n",
      "\t& Clenhaw & 86.20\\tpm{0.77} & 72.98\\tpm{7.28} & 78.04\\tpm{19.26} & 28.73\\tpm{4.31} & 30.90\\tpm{6.81} & 32.73\\tpm{2.94} & \\rkc{38.03\\tpm{1.20}} & 65.92\\tpm{1.98} & \\rkb{44.07\\tpm{0.08}} & \\rkc{85.18\\tpm{0.58}} & 78.58\\tpm{0.78} & 96.96\\tpm{0.03} & 37.13\\tpm{1.85} & \\rka{83.41\\tpm{0.76}} \\\\\n",
      "\t& Bernstein & 74.37\\tpm{0.85} & 57.86\\tpm{22.35} & 76.97\\tpm{17.77} & 34.17\\tpm{0.08} & \\rkc{36.70\\tpm{3.24}} & 35.36\\tpm{3.25} & 37.17\\tpm{1.26} & 61.91\\tpm{1.59} & 37.36\\tpm{1.23} & 78.30\\tpm{4.76} & 78.52\\tpm{0.48} & 96.64\\tpm{0.33} & \\rkb{37.65\\tpm{0.88}} & 77.75\\tpm{0.61} \\\\\n",
      "\t& AdaGNN & 88.60\\tpm{0.95} & 76.69\\tpm{1.17} & 89.66\\tpm{0.32} & \\rka{37.41\\tpm{1.81}} & 35.58\\tpm{1.72} & 36.11\\tpm{2.69} & \\rka{38.07\\tpm{0.83}} & \\rkb{66.73\\tpm{1.69}} & 43.45\\tpm{2.62} & 82.37\\tpm{0.98} & 78.24\\tpm{0.65} & 96.96\\tpm{0.03} & \\rka{38.36\\tpm{0.80}} & \\rkc{81.87\\tpm{0.11}} \\\\\n",
      "\t& ACMGNN & 71.66\\tpm{1.72} & 38.32\\tpm{4.20} & 87.96\\tpm{0.76} & 31.36\\tpm{0.51} & 31.84\\tpm{4.14} & \\rkc{37.84\\tpm{2.29}} & 32.68\\tpm{2.96} & 64.02\\tpm{6.26} & 40.36\\tpm{1.10} & \\rka{90.00\\tpm{0.82}} & 78.51\\tpm{0.31} & 96.96\\tpm{0.03} & 29.30\\tpm{4.09} & 69.61\\tpm{1.87} \\\\\n",
      "\t& FAGNN & 88.29\\tpm{1.07} & 74.71\\tpm{0.44} & 83.77\\tpm{0.59} & 25.92\\tpm{1.27} & 36.33\\tpm{1.81} & 34.68\\tpm{2.06} & 24.61\\tpm{1.45} & 28.82\\tpm{0.75} & 42.57\\tpm{0.32} & 71.00\\tpm{13.74} & \\rkc{78.79\\tpm{0.54}} & 96.95\\tpm{0.04} & 24.08\\tpm{1.03} & 55.30\\tpm{2.81} \\\\\n",
      "\t& G$^2$CN & 82.25\\tpm{3.11} & \\rkb{77.40\\tpm{0.67}} & 88.27\\tpm{0.39} & 24.56\\tpm{0.27} & 30.52\\tpm{0.65} & 33.71\\tpm{2.48} & 34.80\\tpm{1.34} & 49.25\\tpm{0.51} & 42.98\\tpm{1.15} & 80.45\\tpm{0.98} & 78.62\\tpm{0.81} & 96.97\\tpm{0.04} & 35.66\\tpm{0.66} & 65.46\\tpm{11.96} \\\\\n",
      "\t& GNN-LF/HF & 85.71\\tpm{0.59} & 74.86\\tpm{0.38} & 88.60\\tpm{0.83} & 37.15\\tpm{1.55} & 34.83\\tpm{3.13} & 21.55\\tpm{2.19} & 35.00\\tpm{1.66} & 64.01\\tpm{0.33} & 41.47\\tpm{0.69} & 79.20\\tpm{3.17} & 78.21\\tpm{0.61} & 96.95\\tpm{0.03} & 35.77\\tpm{0.94} & 75.21\\tpm{0.33} \\\\\n",
      "\t& FiGURe & \\rkc{88.60\\tpm{0.28}} & \\rka{77.96\\tpm{0.64}} & \\rkb{89.70\\tpm{0.16}} & 35.35\\tpm{0.94} & \\rkb{36.70\\tpm{1.81}} & \\rkb{39.49\\tpm{0.57}} & \\rkb{38.05\\tpm{0.99}} & 64.28\\tpm{2.61} & 42.63\\tpm{0.79} & 80.85\\tpm{0.93} & 78.14\\tpm{0.45} & 96.96\\tpm{0.03} & 35.75\\tpm{1.46} & \\rkb{83.31\\tpm{0.36}} \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in acc_str.index:\n",
    "    print(\"\\t& \" + row + \" & \" + \" & \".join(acc_str.loc[row].values) + \" \\\\\\\\\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex - Eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">cora</th>\n",
       "      <th colspan=\"3\" halign=\"left\">citeseer</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pubmed</th>\n",
       "      <th>flickr</th>\n",
       "      <th>...</th>\n",
       "      <th>tolokers</th>\n",
       "      <th colspan=\"3\" halign=\"left\">questions</th>\n",
       "      <th colspan=\"3\" halign=\"left\">reddit</th>\n",
       "      <th colspan=\"3\" halign=\"left\">penn94</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>time_learn</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>...</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "      <th>time_learn</th>\n",
       "      <th>time_eval</th>\n",
       "      <th>mem_cuda_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Identity</th>\n",
       "      <td>\\rko{3.45}</td>\n",
       "      <td>\\rko{0.30}</td>\n",
       "      <td>\\rko{0.04}</td>\n",
       "      <td>\\rko{3.95}</td>\n",
       "      <td>\\rko{0.40}</td>\n",
       "      <td>\\rko{0.08}</td>\n",
       "      <td>\\rko{3.85}</td>\n",
       "      <td>\\rko{0.43}</td>\n",
       "      <td>\\rko{0.10}</td>\n",
       "      <td>\\rko{3.91}</td>\n",
       "      <td>...</td>\n",
       "      <td>\\rko{0.07}</td>\n",
       "      <td>\\rko{4.71}</td>\n",
       "      <td>\\rko{2.20}</td>\n",
       "      <td>\\rko{0.18}</td>\n",
       "      <td>\\rko{3.45}</td>\n",
       "      <td>\\rko{0.50}</td>\n",
       "      <td>\\rko{0.06}</td>\n",
       "      <td>\\rko{9.03}</td>\n",
       "      <td>\\rko{1.93}</td>\n",
       "      <td>\\rko{0.93}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impulse</th>\n",
       "      <td>\\rka{6.07}</td>\n",
       "      <td>1.37</td>\n",
       "      <td>\\rka{0.06}</td>\n",
       "      <td>7.56</td>\n",
       "      <td>\\rka{1.10}</td>\n",
       "      <td>\\rka{0.10}</td>\n",
       "      <td>\\rka{10.84}</td>\n",
       "      <td>2.17</td>\n",
       "      <td>\\rka{0.21}</td>\n",
       "      <td>\\rka{9.11}</td>\n",
       "      <td>...</td>\n",
       "      <td>\\rka{0.14}</td>\n",
       "      <td>\\rka{22.76}</td>\n",
       "      <td>\\rkc{6.10}</td>\n",
       "      <td>\\rka{0.45}</td>\n",
       "      <td>\\rka{8.34}</td>\n",
       "      <td>\\rka{1.00}</td>\n",
       "      <td>\\rkb{0.11}</td>\n",
       "      <td>\\rka{57.11}</td>\n",
       "      <td>\\rkb{6.87}</td>\n",
       "      <td>\\rka{1.19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monomial</th>\n",
       "      <td>\\rka{6.10}</td>\n",
       "      <td>\\rka{1.07}</td>\n",
       "      <td>\\rka{0.06}</td>\n",
       "      <td>\\rka{6.45}</td>\n",
       "      <td>\\rkc{1.20}</td>\n",
       "      <td>\\rka{0.10}</td>\n",
       "      <td>\\rka{10.77}</td>\n",
       "      <td>\\rkb{2.03}</td>\n",
       "      <td>\\rka{0.21}</td>\n",
       "      <td>\\rka{8.77}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>\\rka{23.27}</td>\n",
       "      <td>\\rka{5.97}</td>\n",
       "      <td>\\rka{0.45}</td>\n",
       "      <td>\\rka{8.93}</td>\n",
       "      <td>1.23</td>\n",
       "      <td>\\rkb{0.11}</td>\n",
       "      <td>\\rka{56.81}</td>\n",
       "      <td>\\rkb{6.83}</td>\n",
       "      <td>\\rka{1.19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPR</th>\n",
       "      <td>\\rka{6.75}</td>\n",
       "      <td>\\rkb{1.23}</td>\n",
       "      <td>\\rka{0.06}</td>\n",
       "      <td>\\rka{6.60}</td>\n",
       "      <td>\\rkc{1.20}</td>\n",
       "      <td>\\rka{0.10}</td>\n",
       "      <td>\\rka{11.16}</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10.05</td>\n",
       "      <td>...</td>\n",
       "      <td>\\rka{0.14}</td>\n",
       "      <td>\\rka{22.76}</td>\n",
       "      <td>\\rkc{6.30}</td>\n",
       "      <td>\\rka{0.45}</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1.23</td>\n",
       "      <td>\\rkb{0.11}</td>\n",
       "      <td>\\rka{57.21}</td>\n",
       "      <td>\\rkb{7.13}</td>\n",
       "      <td>\\rka{1.19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HK</th>\n",
       "      <td>\\rka{7.10}</td>\n",
       "      <td>1.33</td>\n",
       "      <td>\\rka{0.06}</td>\n",
       "      <td>\\rka{6.80}</td>\n",
       "      <td>\\rkc{1.23}</td>\n",
       "      <td>\\rka{0.10}</td>\n",
       "      <td>\\rka{10.46}</td>\n",
       "      <td>\\rkb{2.13}</td>\n",
       "      <td>\\rka{0.21}</td>\n",
       "      <td>\\rkc{9.66}</td>\n",
       "      <td>...</td>\n",
       "      <td>\\rka{0.14}</td>\n",
       "      <td>\\rka{22.11}</td>\n",
       "      <td>\\rkc{6.17}</td>\n",
       "      <td>0.47</td>\n",
       "      <td>\\rka{9.17}</td>\n",
       "      <td>\\rkb{1.03}</td>\n",
       "      <td>\\rkb{0.11}</td>\n",
       "      <td>\\rka{57.62}</td>\n",
       "      <td>\\rkb{6.87}</td>\n",
       "      <td>\\rka{1.19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>\\rka{7.08}</td>\n",
       "      <td>1.40</td>\n",
       "      <td>\\rka{0.06}</td>\n",
       "      <td>\\rka{6.18}</td>\n",
       "      <td>\\rkc{1.30}</td>\n",
       "      <td>0.10</td>\n",
       "      <td>\\rka{10.67}</td>\n",
       "      <td>\\rka{1.83}</td>\n",
       "      <td>0.21</td>\n",
       "      <td>\\rkc{9.59}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>\\rka{23.27}</td>\n",
       "      <td>\\rka{6.07}</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>\\rka{56.88}</td>\n",
       "      <td>\\rka{6.10}</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var-Monomial</th>\n",
       "      <td>\\rka{7.72}</td>\n",
       "      <td>\\rkb{1.13}</td>\n",
       "      <td>\\rka{0.06}</td>\n",
       "      <td>\\rka{6.04}</td>\n",
       "      <td>\\rka{1.00}</td>\n",
       "      <td>\\rka{0.10}</td>\n",
       "      <td>\\rka{11.26}</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>\\rkc{9.28}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>\\rka{23.23}</td>\n",
       "      <td>6.70</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.55</td>\n",
       "      <td>\\rkc{1.13}</td>\n",
       "      <td>\\rka{0.11}</td>\n",
       "      <td>\\rka{57.84}</td>\n",
       "      <td>\\rkb{6.90}</td>\n",
       "      <td>\\rka{1.19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horner</th>\n",
       "      <td>11.84</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.12</td>\n",
       "      <td>16.28</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>30.09</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.73</td>\n",
       "      <td>13.88</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.15</td>\n",
       "      <td>64.60</td>\n",
       "      <td>10.57</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chebyshev</th>\n",
       "      <td>8.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>12.53</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>16.54</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>13.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>30.07</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0.73</td>\n",
       "      <td>15.71</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.15</td>\n",
       "      <td>65.71</td>\n",
       "      <td>8.37</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChebInterp</th>\n",
       "      <td>36.65</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.07</td>\n",
       "      <td>36.35</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.12</td>\n",
       "      <td>49.25</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.34</td>\n",
       "      <td>35.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>62.52</td>\n",
       "      <td>13.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>44.12</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0.15</td>\n",
       "      <td>119.75</td>\n",
       "      <td>11.90</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clenhaw</th>\n",
       "      <td>13.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.07</td>\n",
       "      <td>13.19</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>12.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>31.69</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0.73</td>\n",
       "      <td>15.23</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.15</td>\n",
       "      <td>65.38</td>\n",
       "      <td>11.77</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernstein</th>\n",
       "      <td>31.65</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0.21</td>\n",
       "      <td>31.59</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>43.52</td>\n",
       "      <td>8.37</td>\n",
       "      <td>1.40</td>\n",
       "      <td>38.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>125.98</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.30</td>\n",
       "      <td>34.08</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.54</td>\n",
       "      <td>323.13</td>\n",
       "      <td>19.20</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaGNN</th>\n",
       "      <td>8.95</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.11</td>\n",
       "      <td>12.42</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>13.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>26.66</td>\n",
       "      <td>\\rkc{6.37}</td>\n",
       "      <td>0.69</td>\n",
       "      <td>10.52</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>60.96</td>\n",
       "      <td>\\rkb{7.07}</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACMGNN</th>\n",
       "      <td>37.41</td>\n",
       "      <td>6.97</td>\n",
       "      <td>0.17</td>\n",
       "      <td>41.03</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>37.95</td>\n",
       "      <td>8.90</td>\n",
       "      <td>1.03</td>\n",
       "      <td>42.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>77.80</td>\n",
       "      <td>13.93</td>\n",
       "      <td>2.40</td>\n",
       "      <td>30.01</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>138.97</td>\n",
       "      <td>12.87</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAGNN</th>\n",
       "      <td>12.84</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9.77</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>20.64</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>48.90</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.73</td>\n",
       "      <td>16.60</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.15</td>\n",
       "      <td>119.39</td>\n",
       "      <td>8.13</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G$^2$CN</th>\n",
       "      <td>16.84</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>16.81</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>32.22</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.55</td>\n",
       "      <td>22.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>85.31</td>\n",
       "      <td>8.90</td>\n",
       "      <td>1.24</td>\n",
       "      <td>23.48</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.23</td>\n",
       "      <td>216.12</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNN-LF/HF</th>\n",
       "      <td>10.56</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.47</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.11</td>\n",
       "      <td>19.91</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>14.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>45.63</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>13.16</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.15</td>\n",
       "      <td>113.96</td>\n",
       "      <td>9.03</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiGURe</th>\n",
       "      <td>39.90</td>\n",
       "      <td>9.23</td>\n",
       "      <td>0.26</td>\n",
       "      <td>36.28</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.35</td>\n",
       "      <td>72.08</td>\n",
       "      <td>19.70</td>\n",
       "      <td>1.72</td>\n",
       "      <td>56.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08</td>\n",
       "      <td>167.02</td>\n",
       "      <td>48.73</td>\n",
       "      <td>4.09</td>\n",
       "      <td>45.25</td>\n",
       "      <td>13.40</td>\n",
       "      <td>0.67</td>\n",
       "      <td>417.21</td>\n",
       "      <td>115.10</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cora                               citeseer              \\\n",
       "              time_learn   time_eval mem_cuda_train  time_learn   time_eval   \n",
       "Identity      \\rko{3.45}  \\rko{0.30}     \\rko{0.04}  \\rko{3.95}  \\rko{0.40}   \n",
       "Impulse       \\rka{6.07}        1.37     \\rka{0.06}        7.56  \\rka{1.10}   \n",
       "Monomial      \\rka{6.10}  \\rka{1.07}     \\rka{0.06}  \\rka{6.45}  \\rkc{1.20}   \n",
       "PPR           \\rka{6.75}  \\rkb{1.23}     \\rka{0.06}  \\rka{6.60}  \\rkc{1.20}   \n",
       "HK            \\rka{7.10}        1.33     \\rka{0.06}  \\rka{6.80}  \\rkc{1.23}   \n",
       "Gaussian      \\rka{7.08}        1.40     \\rka{0.06}  \\rka{6.18}  \\rkc{1.30}   \n",
       "Var-Monomial  \\rka{7.72}  \\rkb{1.13}     \\rka{0.06}  \\rka{6.04}  \\rka{1.00}   \n",
       "Horner             11.84        1.90           0.07        8.25        1.97   \n",
       "Chebyshev           8.85        1.60           0.07       12.53        1.93   \n",
       "ChebInterp         36.65        6.47           0.07       36.35        6.60   \n",
       "Clenhaw            13.33        1.97           0.07       13.19        2.27   \n",
       "Bernstein          31.65        7.63           0.21       31.59        8.33   \n",
       "AdaGNN              8.95        1.47           0.07        9.45        1.53   \n",
       "ACMGNN             37.41        6.97           0.17       41.03        7.33   \n",
       "FAGNN              12.84        2.70           0.07        9.77        2.17   \n",
       "G$^2$CN            16.84        3.13           0.10       16.81        2.60   \n",
       "GNN-LF/HF          10.56        2.03           0.07        8.47        1.83   \n",
       "FiGURe             39.90        9.23           0.26       36.28        9.60   \n",
       "\n",
       "                                  pubmed                             \\\n",
       "             mem_cuda_train   time_learn   time_eval mem_cuda_train   \n",
       "Identity         \\rko{0.08}   \\rko{3.85}  \\rko{0.43}     \\rko{0.10}   \n",
       "Impulse          \\rka{0.10}  \\rka{10.84}        2.17     \\rka{0.21}   \n",
       "Monomial         \\rka{0.10}  \\rka{10.77}  \\rkb{2.03}     \\rka{0.21}   \n",
       "PPR              \\rka{0.10}  \\rka{11.16}        2.30           0.22   \n",
       "HK               \\rka{0.10}  \\rka{10.46}  \\rkb{2.13}     \\rka{0.21}   \n",
       "Gaussian               0.10  \\rka{10.67}  \\rka{1.83}           0.21   \n",
       "Var-Monomial     \\rka{0.10}  \\rka{11.26}        2.23           0.22   \n",
       "Horner                 0.12        16.28        5.10           0.34   \n",
       "Chebyshev              0.11        16.54        4.07           0.33   \n",
       "ChebInterp             0.12        49.25        7.80           0.34   \n",
       "Clenhaw                0.12        17.95        5.23           0.34   \n",
       "Bernstein              0.29        43.52        8.37           1.40   \n",
       "AdaGNN                 0.11        12.42        3.17           0.31   \n",
       "ACMGNN                 0.24        37.95        8.90           1.03   \n",
       "FAGNN                  0.12        20.64        4.07           0.33   \n",
       "G$^2$CN                0.15        32.22        5.03           0.55   \n",
       "GNN-LF/HF              0.11        19.91        4.27           0.33   \n",
       "FiGURe                 0.35        72.08       19.70           1.72   \n",
       "\n",
       "                  flickr  ...       tolokers    questions              \\\n",
       "              time_learn  ... mem_cuda_train   time_learn   time_eval   \n",
       "Identity      \\rko{3.91}  ...     \\rko{0.07}   \\rko{4.71}  \\rko{2.20}   \n",
       "Impulse       \\rka{9.11}  ...     \\rka{0.14}  \\rka{22.76}  \\rkc{6.10}   \n",
       "Monomial      \\rka{8.77}  ...           0.14  \\rka{23.27}  \\rka{5.97}   \n",
       "PPR                10.05  ...     \\rka{0.14}  \\rka{22.76}  \\rkc{6.30}   \n",
       "HK            \\rkc{9.66}  ...     \\rka{0.14}  \\rka{22.11}  \\rkc{6.17}   \n",
       "Gaussian      \\rkc{9.59}  ...           0.17  \\rka{23.27}  \\rka{6.07}   \n",
       "Var-Monomial  \\rkc{9.28}  ...           0.14  \\rka{23.23}        6.70   \n",
       "Horner             11.61  ...           0.23        30.09       11.93   \n",
       "Chebyshev          13.47  ...           0.23        30.07        9.43   \n",
       "ChebInterp         35.70  ...           0.24        62.52       13.80   \n",
       "Clenhaw            12.44  ...           0.23        31.69       12.97   \n",
       "Bernstein          38.74  ...           0.87       125.98       12.73   \n",
       "AdaGNN             13.11  ...           0.22        26.66  \\rkc{6.37}   \n",
       "ACMGNN             42.22  ...           0.63        77.80       13.93   \n",
       "FAGNN              12.21  ...           0.21        48.90        8.33   \n",
       "G$^2$CN            22.12  ...           0.33        85.31        8.90   \n",
       "GNN-LF/HF          14.41  ...           0.20        45.63        8.40   \n",
       "FiGURe             56.53  ...           1.08       167.02       48.73   \n",
       "\n",
       "                                 reddit                             \\\n",
       "             mem_cuda_train  time_learn   time_eval mem_cuda_train   \n",
       "Identity         \\rko{0.18}  \\rko{3.45}  \\rko{0.50}     \\rko{0.06}   \n",
       "Impulse          \\rka{0.45}  \\rka{8.34}  \\rka{1.00}     \\rkb{0.11}   \n",
       "Monomial         \\rka{0.45}  \\rka{8.93}        1.23     \\rkb{0.11}   \n",
       "PPR              \\rka{0.45}        9.66        1.23     \\rkb{0.11}   \n",
       "HK                     0.47  \\rka{9.17}  \\rkb{1.03}     \\rkb{0.11}   \n",
       "Gaussian               0.48        9.87        1.50           0.11   \n",
       "Var-Monomial           0.47       10.55  \\rkc{1.13}     \\rka{0.11}   \n",
       "Horner                 0.73       13.88        2.93           0.15   \n",
       "Chebyshev              0.73       15.71        2.77           0.15   \n",
       "ChebInterp             0.76       44.12        7.57           0.15   \n",
       "Clenhaw                0.73       15.23        3.53           0.15   \n",
       "Bernstein              3.30       34.08        7.07           0.54   \n",
       "AdaGNN                 0.69       10.52        1.40           0.14   \n",
       "ACMGNN                 2.40       30.01        7.33           0.41   \n",
       "FAGNN                  0.73       16.60        1.93           0.15   \n",
       "G$^2$CN                1.24       23.48        2.30           0.23   \n",
       "GNN-LF/HF              0.70       13.16        1.90           0.15   \n",
       "FiGURe                 4.09       45.25       13.40           0.67   \n",
       "\n",
       "                   penn94                             \n",
       "               time_learn   time_eval mem_cuda_train  \n",
       "Identity       \\rko{9.03}  \\rko{1.93}     \\rko{0.93}  \n",
       "Impulse       \\rka{57.11}  \\rkb{6.87}     \\rka{1.19}  \n",
       "Monomial      \\rka{56.81}  \\rkb{6.83}     \\rka{1.19}  \n",
       "PPR           \\rka{57.21}  \\rkb{7.13}     \\rka{1.19}  \n",
       "HK            \\rka{57.62}  \\rkb{6.87}     \\rka{1.19}  \n",
       "Gaussian      \\rka{56.88}  \\rka{6.10}           1.26  \n",
       "Var-Monomial  \\rka{57.84}  \\rkb{6.90}     \\rka{1.19}  \n",
       "Horner              64.60       10.57           1.49  \n",
       "Chebyshev           65.71        8.37           1.48  \n",
       "ChebInterp         119.75       11.90           1.49  \n",
       "Clenhaw             65.38       11.77           1.49  \n",
       "Bernstein          323.13       19.20           3.70  \n",
       "AdaGNN              60.96  \\rkb{7.07}           1.44  \n",
       "ACMGNN             138.97       12.87           2.88  \n",
       "FAGNN              119.39        8.13           1.43  \n",
       "G$^2$CN            216.12        9.20           1.86  \n",
       "GNN-LF/HF          113.96        9.03           1.39  \n",
       "FiGURe             417.21      115.10           4.45  \n",
       "\n",
       "[18 rows x 42 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlst = [\"time_learn\", \"time_eval\", \"mem_cuda_train\"]\n",
    "eff_str = pd.DataFrame(index=flst, columns=pd.MultiIndex.from_product([dlst, mlst]))\n",
    "\n",
    "for row in eff_str.index:\n",
    "    for data, met in eff_str.columns:\n",
    "        mean = df.loc[(df['name'] == row) & (df['data'] == data), met+'_mean'].values\n",
    "        std = df.loc[(df['name'] == row) & (df['data'] == data), met+'_std'].values\n",
    "        if len(mean) > 0:\n",
    "            eff_str.loc[row, (data, met)] = f\"{mean[0]:.2f}\"\n",
    "\n",
    "for data,met in eff_str.columns:\n",
    "    mean = df.loc[df['data'] == data, ['name', met+'_mean']].set_index('name')[met+'_mean'].astype(float)\n",
    "    std  = df.loc[df['data'] == data, ['name', met+'_std']].set_index('name')[met+'_std'].astype(float)\n",
    "    rank = calc_ranks(mean, std, True, ['Identity'])\n",
    "    for i, rki in enumerate(rk):\n",
    "        idx = rank[rank == i+1].index\n",
    "        eff_str.loc[idx, (data, met)] = f'\\\\rk{rki}' + '{' + eff_str.loc[idx, (data, met)] + '}'\n",
    "    eff_str.loc[rank.isna(), (data, met)] = '\\\\rko{' + eff_str.loc[rank.isna(), (data, met)].astype(str) + '}'\n",
    "\n",
    "eff_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t& Identity & \\rko{3.91} & \\rko{0.50} & \\rko{0.06} & \\rko{3.45} & \\rko{0.50} & \\rko{0.06} & \\rko{3.60} & \\rko{0.60} & \\rko{0.07} & \\rko{9.03} & \\rko{1.93} & \\rko{0.93} \\\\\n",
      "\t& Impulse & \\rka{9.11} & \\rkb{1.10} & 0.11 & \\rka{8.34} & \\rka{1.00} & \\rkb{0.11} & \\rka{21.71} & \\rkb{1.67} & \\rka{0.14} & \\rka{57.11} & \\rkb{6.87} & \\rka{1.19} \\\\\n",
      "\t& Monomial & \\rka{8.77} & \\rkb{1.03} & \\rka{0.10} & \\rka{8.93} & 1.23 & \\rkb{0.11} & \\rka{21.94} & \\rkb{1.50} & 0.14 & \\rka{56.81} & \\rkb{6.83} & \\rka{1.19} \\\\\n",
      "\t& PPR & 10.05 & \\rka{0.97} & \\rka{0.10} & 9.66 & 1.23 & \\rkb{0.11} & \\rka{22.81} & \\rkb{1.57} & \\rka{0.14} & \\rka{57.21} & \\rkb{7.13} & \\rka{1.19} \\\\\n",
      "\t& HK & \\rkc{9.66} & 1.20 & 0.11 & \\rka{9.17} & \\rkb{1.03} & \\rkb{0.11} & \\rka{21.93} & \\rkb{1.50} & \\rka{0.14} & \\rka{57.62} & \\rkb{6.87} & \\rka{1.19} \\\\\n",
      "\t& Gaussian & \\rkc{9.59} & 1.50 & 0.11 & 9.87 & 1.50 & 0.11 & \\rka{22.47} & \\rka{1.33} & 0.17 & \\rka{56.88} & \\rka{6.10} & 1.26 \\\\\n",
      "\t& Var-Monomial & \\rkc{9.28} & 1.27 & \\rkc{0.11} & 10.55 & \\rkc{1.13} & \\rka{0.11} & 23.75 & 1.77 & 0.14 & \\rka{57.84} & \\rkb{6.90} & \\rka{1.19} \\\\\n",
      "\t& Horner & 11.61 & 2.47 & 0.15 & 13.88 & 2.93 & 0.15 & 27.34 & 2.97 & 0.23 & 64.60 & 10.57 & 1.49 \\\\\n",
      "\t& Chebyshev & 13.47 & 2.60 & 0.15 & 15.71 & 2.77 & 0.15 & 26.14 & 2.63 & 0.23 & 65.71 & 8.37 & 1.48 \\\\\n",
      "\t& ChebInterp & 35.70 & 7.20 & 0.15 & 44.12 & 7.57 & 0.15 & 59.36 & 9.63 & 0.24 & 119.75 & 11.90 & 1.49 \\\\\n",
      "\t& Clenhaw & 12.44 & 2.80 & 0.15 & 15.23 & 3.53 & 0.15 & 25.75 & 3.17 & 0.23 & 65.38 & 11.77 & 1.49 \\\\\n",
      "\t& Bernstein & 38.74 & 8.03 & 0.55 & 34.08 & 7.07 & 0.54 & 128.71 & 7.37 & 0.87 & 323.13 & 19.20 & 3.70 \\\\\n",
      "\t& AdaGNN & 13.11 & 1.97 & 0.14 & 10.52 & 1.40 & 0.14 & 23.85 & \\rkb{1.53} & 0.22 & 60.96 & \\rkb{7.07} & 1.44 \\\\\n",
      "\t& ACMGNN & 42.22 & 7.40 & 0.41 & 30.01 & 7.33 & 0.41 & 64.56 & 7.93 & 0.63 & 138.97 & 12.87 & 2.88 \\\\\n",
      "\t& FAGNN & 12.21 & 1.93 & 0.15 & 16.60 & 1.93 & 0.15 & 46.09 & 3.13 & 0.21 & 119.39 & 8.13 & 1.43 \\\\\n",
      "\t& G$^2$CN & 22.12 & 2.40 & 0.23 & 23.48 & 2.30 & 0.23 & 84.99 & 4.70 & 0.33 & 216.12 & 9.20 & 1.86 \\\\\n",
      "\t& GNN-LF/HF & 14.41 & 1.90 & 0.15 & 13.16 & 1.90 & 0.15 & 44.98 & 3.10 & 0.20 & 113.96 & 9.03 & 1.39 \\\\\n",
      "\t& FiGURe & 56.53 & 13.70 & 0.67 & 45.25 & 13.40 & 0.67 & 169.32 & 43.80 & 1.08 & 417.21 & 115.10 & 4.45 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlst_eff = [\"flickr\", \"reddit\", \"tolokers\", \"penn94\"]\n",
    "for row in eff_str.index:\n",
    "    print(\"\\t& \" + row + \" & \" + \" & \".join(eff_str.loc[row, dlst_eff].values) + \" \\\\\\\\\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
